# DCN + SCC ç»„åˆC2fæ¨¡å—å®ç°
# =========================

"""
YOLOv8çš„DCN + SCCç»„åˆC2fæ¨¡å—

åœ¨C2få—ä¸­ç»“åˆå¯å˜å½¢å·ç§¯ç½‘ç»œå’Œç©ºé—´-é€šé“äº¤å‰æ³¨æ„åŠ›ï¼Œ
å®ç°æœ€ä¼˜çš„ç‰¹å¾è¡¨ç¤ºå’Œå‡ ä½•å»ºæ¨¡èƒ½åŠ›ã€‚
"""

import torch
import torch.nn as nn
from ultralytics.nn.modules.block import C2f

# å¤„ç†ç›´æ¥è¿è¡Œå’ŒåŒ…å¯¼å…¥ä¸¤ç§æƒ…å†µ
try:
    # å½“ä½œä¸ºåŒ…çš„ä¸€éƒ¨åˆ†å¯¼å…¥æ—¶
    from .dcn_scc_attention import DCN_SCC_Bottleneck, Enhanced_DCN_SCC_Conv
except ImportError:
    # å½“ç›´æ¥è¿è¡Œæˆ–ä»å¤–éƒ¨å¯¼å…¥æ—¶
    from dcn_scc_attention import DCN_SCC_Bottleneck, Enhanced_DCN_SCC_Conv


class DCN_SCC_C2f(C2f):
    """
    DCN + SCCç»„åˆå¢å¼ºçš„C2fæ¨¡å—

    å°†æ ‡å‡†Bottleneckå—æ›¿æ¢ä¸ºDCN+SCCå¢å¼ºç‰ˆæœ¬ï¼Œ
    ç”¨äºå“è¶Šçš„ç‰¹å¾æå–å’Œå‡ ä½•å»ºæ¨¡ã€‚

    æ¶æ„ç‰¹ç‚¹ï¼š
        - ç»§æ‰¿æ ‡å‡†C2fçš„CSPè®¾è®¡ç†å¿µ
        - é›†æˆDCNçš„å‡ ä½•å˜æ¢å»ºæ¨¡èƒ½åŠ›
        - åŠ å…¥SCCçš„ç©ºé—´-é€šé“æ³¨æ„åŠ›æœºåˆ¶
        - ä¿æŒä¸YOLOv8çš„å®Œå…¨å…¼å®¹æ€§

    æŠ€æœ¯ä¼˜åŠ¿ï¼š
        - å‡ ä½•å»ºæ¨¡ï¼šå¤„ç†å˜å½¢å’Œä¸è§„åˆ™å½¢çŠ¶ç‰©ä½“
        - æ³¨æ„åŠ›å¢å¼ºï¼šä¼˜åŒ–ç‰¹å¾é€‰æ‹©å’Œè¡¨è¾¾
        - å¤šå°ºåº¦å¤„ç†ï¼šé€‚åº”ä¸åŒå¤§å°çš„ç›®æ ‡æ£€æµ‹
        - è®¡ç®—æ•ˆç‡ï¼šä¼˜åŒ–çš„ç½‘ç»œç»“æ„è®¾è®¡

    åº”ç”¨åœºæ™¯ï¼š
        - YOLOv8ä¸»å¹²ç½‘ç»œçš„å…³é”®ç‰¹å¾å±‚
        - éœ€è¦å‡ ä½•å»ºæ¨¡å’Œæ³¨æ„åŠ›å¢å¼ºçš„ä»»åŠ¡
        - å¯¹æ£€æµ‹ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„åº”ç”¨
    """

    def __init__(self, c1, c2, n=1, shortcut=False, g=1, e=0.5):
        """
        åˆå§‹åŒ–DCN + SCCå¢å¼ºçš„C2fæ¨¡å—

        å‚æ•°ï¼š
            c1 (int): è¾“å…¥é€šé“æ•°
            c2 (int): è¾“å‡ºé€šé“æ•°
            n (int): DCN_SCCç“¶é¢ˆå—çš„æ•°é‡ï¼Œé»˜è®¤1
            shortcut (bool): æ˜¯å¦ä½¿ç”¨æ®‹å·®è¿æ¥ï¼Œé»˜è®¤False
            g (int): å·ç§¯åˆ†ç»„æ•°ï¼Œé»˜è®¤1
            e (float): éšè—å±‚é€šé“æ‰©å±•æ¯”ä¾‹ï¼Œé»˜è®¤0.5

        ç½‘ç»œç»“æ„ï¼š
            è¾“å…¥ -> 1x1å·ç§¯åˆ†æ”¯ -> åˆ†å‰²ä¸ºä¸¤è·¯ -> DCN_SCCç“¶é¢ˆå—å¤„ç† -> æ‹¼æ¥ -> 1x1è¾“å‡ºå·ç§¯
            |                        |                      |
            +------------------------+----------------------+

        è®¾è®¡ç†å¿µï¼š
            - CSPæ¶æ„ï¼šå‡å°‘è®¡ç®—é‡ï¼Œæé«˜ç‰¹å¾é‡ç”¨
            - DCNå¢å¼ºï¼šæ¯ä¸ªç“¶é¢ˆå—éƒ½æœ‰å‡ ä½•å»ºæ¨¡èƒ½åŠ›
            - SCCä¼˜åŒ–ï¼šé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶æå‡ç‰¹å¾è´¨é‡
            - æ¨¡å—åŒ–è®¾è®¡ï¼šä¾¿äºé›†æˆå’Œæ‰©å±•
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–åŸºç¡€ç»“æ„
        super().__init__(c1, c2, n=n, shortcut=shortcut, g=g, e=e)

        # æ ¸å¿ƒåˆ›æ–°ï¼šå°†æ ‡å‡†ç“¶é¢ˆå—æ›¿æ¢ä¸ºDCN+SCCå¢å¼ºç‰ˆæœ¬
        self.m = nn.ModuleList(
            DCN_SCC_Bottleneck(self.c, self.c, shortcut=shortcut, g=g, e=1.0, use_scc=True)
            for _ in range(n)
        )

    def forward(self, x):
        """
        DCN+SCCå¢å¼ºçš„C2få‰å‘ä¼ æ’­

        å‚æ•°ï¼š
            x (torch.Tensor): è¾“å…¥ç‰¹å¾å›¾ï¼Œå½¢çŠ¶ä¸º[B, C1, H, W]

        è¿”å›å€¼ï¼š
            torch.Tensor: è¾“å‡ºç‰¹å¾å›¾ï¼Œå½¢çŠ¶ä¸º[B, C2, H, W]

        å¤„ç†æµç¨‹ï¼š
            1. è¾“å…¥é¢„å¤„ç†å’Œåˆ†æ”¯åˆ†å‰²ï¼ˆCSPç»“æ„ï¼‰
            2. DCN_SCCç“¶é¢ˆå—çš„å¹¶è¡Œå‡ ä½•å»ºæ¨¡å’Œæ³¨æ„åŠ›å¢å¼º
            3. å¤šåˆ†æ”¯ç‰¹å¾æ‹¼æ¥èåˆ
            4. æœ€ç»ˆè¾“å‡ºå·ç§¯

        æŠ€æœ¯ç‰¹ç‚¹ï¼š
            - åˆ†æ”¯å¤„ç†ï¼šå¹¶è¡Œè®¡ç®—æé«˜æ•ˆç‡
            - å‡ ä½•å»ºæ¨¡ï¼šDCNå­¦ä¹ ç©ºé—´å˜æ¢å‚æ•°
            - æ³¨æ„åŠ›ä¼˜åŒ–ï¼šSCCè¿›è¡Œç‰¹å¾é‡æ ‡å®š
            - ç‰¹å¾èåˆï¼šæœ‰æ•ˆçš„å¤šè·¯ä¿¡æ¯æ•´åˆ

        æ€§èƒ½ä¼˜åŠ¿ï¼š
            - æ£€æµ‹ç²¾åº¦ï¼šå‡ ä½•å»ºæ¨¡æå‡å˜å½¢ç‰©ä½“æ£€æµ‹
            - ç‰¹å¾è´¨é‡ï¼šæ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–è¡¨è¾¾èƒ½åŠ›
            - è®¡ç®—æ•ˆç‡ï¼šCSPè®¾è®¡å‡å°‘å†—ä½™è®¡ç®—
        """
        # CSPåˆ†æ”¯åˆ†å‰²ï¼šå°†è¾“å…¥ç‰¹å¾åˆ†ä¸ºä¸¤ä¸ªåˆ†æ”¯è¿›è¡Œå¹¶è¡Œå¤„ç†
        y = list(self.cv1(x).chunk(2, 1))

        # åº”ç”¨DCN+SCCå¢å¼ºçš„ç“¶é¢ˆå—
        # æ¯ä¸ªç“¶é¢ˆå—éƒ½åŒ…å«å‡ ä½•å»ºæ¨¡å’Œæ³¨æ„åŠ›å¢å¼º
        for m in self.m:
            y.append(m(y[-1]))

        # æ‹¼æ¥æ‰€æœ‰åˆ†æ”¯å¹¶è¿›è¡Œæœ€ç»ˆå·ç§¯è¾“å‡º
        return self.cv2(torch.cat(y, 1))


class Enhanced_DCN_SCC_C2f(nn.Module):
    """
    é«˜çº§å¢å¼ºç‰ˆçš„DCN + SCC C2fæ¨¡å—

    ç‰¹æ€§ï¼š
    - DCN + SCCç“¶é¢ˆå—é›†æˆ
    - å¢å¼ºçš„ç‰¹å¾èåˆæœºåˆ¶
    - å¤šå°ºåº¦æ³¨æ„åŠ›æœºåˆ¶
    - è‡ªé€‚åº”ç‰¹å¾å¤„ç†
    - ä¼˜åŒ–çš„è®¡ç®—æ•ˆç‡

    æ¶æ„åˆ›æ–°ï¼š
        - ç‹¬ç«‹å®ç°ï¼Œä¸ä¾èµ–æ ‡å‡†C2f
        - å¤šå±‚æ¬¡ç‰¹å¾å¤„ç†
        - å¢å¼ºçš„èåˆç­–ç•¥
        - è‡ªé€‚åº”æ³¨æ„åŠ›è°ƒèŠ‚

    æŠ€æœ¯ä¼˜åŠ¿ï¼š
        - æ›´å¼ºçš„å‡ ä½•å»ºæ¨¡èƒ½åŠ›
        - æ›´ç²¾ç»†çš„æ³¨æ„åŠ›æ§åˆ¶
        - æ›´å¥½çš„ç‰¹å¾èåˆæ•ˆæœ
        - æ›´é«˜çš„è®¡ç®—æ•ˆç‡

    åº”ç”¨åœºæ™¯ï¼š
        - é«˜ç²¾åº¦ç›®æ ‡æ£€æµ‹ä»»åŠ¡
        - å¤æ‚åœºæ™¯çš„ç‰¹å¾æå–
        - å¯¹æ€§èƒ½è¦æ±‚æé«˜çš„åº”ç”¨
    """

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        """
        Args:
            c1: input channels
            c2: output channels
            n: number of enhanced bottleneck blocks
            shortcut: residual connection flag
            g: convolution groups
            e: expansion ratio
        """
        super().__init__()

        self.c = int(c2 * e)  # hidden channels

        # Enhanced input processing with DCN+SCC
        self.cv1 = nn.Sequential(
            nn.Conv2d(c1, 2 * self.c, 1, 1, bias=False),
            nn.BatchNorm2d(2 * self.c),
            nn.SiLU()
        )

        # DCN + SCC bottleneck blocks
        self.m = nn.ModuleList(
            DCN_SCC_Bottleneck(self.c, self.c, shortcut=shortcut, g=g, use_scc=True)
            for _ in range(n)
        )

        # Enhanced output processing
        self.cv2 = nn.Sequential(
            nn.Conv2d((2 + n) * self.c, c2, 1, 1, bias=False),
            nn.BatchNorm2d(c2),
            nn.SiLU()
        )

        # Additional feature refinement
        self.refinement = Enhanced_DCN_SCC_Conv(c2, c2, k=3, s=1, p=1)

    def forward(self, x):
        """
        Enhanced forward pass with multi-stage processing

        Args:
            x: input tensor [B, C1, H, W]

        Returns:
            output tensor [B, C2, H, W]
        """
        y = list(self.cv1(x).chunk(2, 1))

        # Apply DCN+SCC bottlenecks
        for m in self.m:
            y.append(m(y[-1]))

        # Primary output
        primary_out = self.cv2(torch.cat(y, 1))

        # Feature refinement with enhanced DCN+SCC
        refined_out = self.refinement(primary_out)

        return refined_out


class Adaptive_DCN_SCC_C2f(nn.Module):
    """
    Adaptive DCN + SCC C2f with Dynamic Feature Selection

    Features:
    - Adaptive bottleneck selection based on input complexity
    - Dynamic SCC attention strength
    - Computational efficiency optimization
    """

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        """
        Args:
            c1: input channels
            c2: output channels
            n: maximum number of bottleneck blocks
            shortcut: residual connection flag
            g: convolution groups
            e: expansion ratio
        """
        super().__init__()

        self.c = int(c2 * e)
        self.n = n

        # Input processing
        self.cv1 = nn.Sequential(
            nn.Conv2d(c1, 2 * self.c, 1, 1, bias=False),
            nn.BatchNorm2d(2 * self.c),
            nn.SiLU()
        )

        # Multiple bottleneck options
        self.m = nn.ModuleList([
            DCN_SCC_Bottleneck(self.c, self.c, shortcut=shortcut, g=g, use_scc=True)
            for _ in range(n)
        ])

        # Adaptive weighting network
        self.adaptive_weight = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(c1, n, 1, 1, bias=False),
            nn.Sigmoid()
        )

        # Output processing
        self.cv2 = nn.Sequential(
            nn.Conv2d((2 + n) * self.c, c2, 1, 1, bias=False),
            nn.BatchNorm2d(c2),
            nn.SiLU()
        )

    def forward(self, x):
        """
        Adaptive forward pass with dynamic bottleneck selection

        Args:
            x: input tensor [B, C1, H, W]

        Returns:
            output tensor [B, C2, H, W]
        """
        # Compute adaptive weights
        weights = self.adaptive_weight(x)  # [B, n, 1, 1]

        # Base features
        y = list(self.cv1(x).chunk(2, 1))

        # Apply weighted bottlenecks
        for i, m in enumerate(self.m):
            bottleneck_out = m(y[-1])
            weight = weights[:, i:i+1, :, :]  # [B, 1, 1, 1]
            y.append(bottleneck_out * weight + y[-1] * (1 - weight))

        return self.cv2(torch.cat(y, 1))


# Runtime replacement function for existing YOLO models
def replace_c2f_with_dcn_scc(model, target_channels=[256, 512], mode='standard'):
    """
    Runtime replacement of C2f blocks with DCN+SCC enhanced versions

    Args:
        model: YOLO model instance
        target_channels: list of channel sizes to replace
        mode: replacement mode ('standard', 'enhanced', 'adaptive')

    Returns:
        modified model with DCN+SCC blocks
    """
    net = model.model if hasattr(model, 'model') else model

    replaced_count = 0
    for name, module in net.named_modules():
        if isinstance(module, C2f):
            try:
                out_channels = module.cv2.conv.out_channels
                if out_channels in target_channels:
                    # Choose replacement type
                    if mode == 'enhanced':
                        dcn_scc_c2f = Enhanced_DCN_SCC_C2f(
                            c1=module.cv1.conv.in_channels,
                            c2=out_channels,
                            n=len(module.m),
                            shortcut=getattr(module, 'shortcut', False),
                            e=getattr(module, 'e', 0.5)
                        )
                    elif mode == 'adaptive':
                        dcn_scc_c2f = Adaptive_DCN_SCC_C2f(
                            c1=module.cv1.conv.in_channels,
                            c2=out_channels,
                            n=len(module.m),
                            shortcut=getattr(module, 'shortcut', False),
                            e=getattr(module, 'e', 0.5)
                        )
                    else:  # standard
                        dcn_scc_c2f = DCN_SCC_C2f(
                            c1=module.cv1.conv.in_channels,
                            c2=out_channels,
                            n=len(module.m),
                            shortcut=getattr(module, 'shortcut', False),
                            e=getattr(module, 'e', 0.5)
                        )

                    # Replace the module
                    parent_name = '.'.join(name.split('.')[:-1])
                    child_name = name.split('.')[-1]

                    if parent_name:
                        parent = net
                        for part in parent_name.split('.'):
                            parent = getattr(parent, part)
                        setattr(parent, child_name, dcn_scc_c2f)
                    else:
                        setattr(net, child_name, dcn_scc_c2f)

                    # Copy Ultralytics-specific attributes that may be needed
                    for attr in ["i", "f", "type", "np"]:
                        if hasattr(module, attr):
                            setattr(dcn_scc_c2f, attr, getattr(module, attr))

                    replaced_count += 1
                    print(f"âœ… Replaced C2f at {name} with DCN+SCC C2f ({mode}, out_channels={out_channels})")

            except Exception as e:
                print(f"âš ï¸  Failed to replace C2f at {name}: {e}")
                continue

    print(f"ğŸ¯ Total DCN+SCC replacements: {replaced_count}")
    return model


# Test the DCN + SCC C2f implementation
if __name__ == "__main__":
    # When run as main script, import from parent directory
    import sys
    from pathlib import Path
    parent_dir = Path(__file__).parent.parent
    if str(parent_dir) not in sys.path:
        sys.path.insert(0, str(parent_dir))

    from utils import setup_device, validate_model, benchmark_inference

    device = setup_device()

    # Test Standard DCN+SCC C2f
    print("\nğŸ”§ Testing DCN_SCC_C2f:")
    dcn_scc_c2f = DCN_SCC_C2f(c1=256, c2=256, n=2, shortcut=True)
    validate_model(dcn_scc_c2f, device, input_size=(1, 256, 32, 32))
    benchmark_inference(dcn_scc_c2f, device, input_size=(1, 256, 32, 32))

    # Test Enhanced version
    print("\nğŸ”§ Testing Enhanced_DCN_SCC_C2f:")
    enhanced_dcn_scc = Enhanced_DCN_SCC_C2f(c1=256, c2=256, n=2, shortcut=True)
    validate_model(enhanced_dcn_scc, device, input_size=(1, 256, 32, 32))
    benchmark_inference(enhanced_dcn_scc, device, input_size=(1, 256, 32, 32))

    # Test Adaptive version
    print("\nğŸ”§ Testing Adaptive_DCN_SCC_C2f:")
    adaptive_dcn_scc = Adaptive_DCN_SCC_C2f(c1=256, c2=256, n=3, shortcut=True)
    validate_model(adaptive_dcn_scc, device, input_size=(1, 256, 32, 32))
    benchmark_inference(adaptive_dcn_scc, device, input_size=(1, 256, 32, 32))

    print("\nâœ… DCN + SCC C2f modules tested successfully!")
    print("ğŸ¯ Combines DCN geometric modeling with SCC attention mechanisms")
    print("ğŸ’¡ Use replace_c2f_with_dcn_scc() to apply combined optimization to existing YOLO models")


class DCN_SCC_C2f_YAML(nn.Module):
    """
    åŸºäºYAMLé…ç½®çš„DCN + SCCç»„åˆå¢å¼ºC2fæ¨¡å—

    æ­¤ç‰ˆæœ¬ä¸“é—¨è®¾è®¡ç”¨äºYAMLé…ç½®æ–‡ä»¶ä¸­ï¼Œ
    å¯ä»¥ç›´æ¥åœ¨YOLOv8æ¶æ„ä¸­æ›¿æ¢æ ‡å‡†C2få—ã€‚

    æŠ€æœ¯ç‰¹ç‚¹ï¼š
        - ç‹¬ç«‹çš„ç½‘ç»œç»“æ„å®ç°ï¼Œä¸ä¾èµ–æ ‡å‡†C2f
        - é›†æˆDCNå‡ ä½•å»ºæ¨¡å’ŒSCCæ³¨æ„åŠ›æœºåˆ¶
        - ä¼˜åŒ–çš„ç‰¹å¾èåˆç­–ç•¥
        - å®Œæ•´çš„å¤šå°ºåº¦å¤„ç†èƒ½åŠ›

    YAMLé…ç½®ç¤ºä¾‹ï¼š
        ```yaml
        backbone:
          - [-1, 6, DCN_SCC_C2f_YAML, [256, True]]  # P3å±‚DCN+SCCç»„åˆå¢å¼º
        ```

    å‚æ•°ï¼š
        c1 (int): è¾“å…¥é€šé“æ•°
        c2 (int): è¾“å‡ºé€šé“æ•°
        n (int): ç“¶é¢ˆå—æ•°é‡ï¼Œé»˜è®¤2
        shortcut (bool): æ˜¯å¦ä½¿ç”¨æ®‹å·®è¿æ¥ï¼Œé»˜è®¤True
        g (int): å·ç§¯åˆ†ç»„æ•°ï¼Œé»˜è®¤1
        e (float): æ‰©å±•æ¯”ä¾‹ï¼Œé»˜è®¤0.5
    """

    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        """
        åˆå§‹åŒ–YAMLé…ç½®ç‰ˆæœ¬çš„DCN+SCCç»„åˆC2fæ¨¡å—

        å‚æ•°ï¼š
            c1 (int): è¾“å…¥é€šé“æ•°
            c2 (int): è¾“å‡ºé€šé“æ•°
            n (int): DCN+SCCç“¶é¢ˆå—çš„æ•°é‡ï¼Œé»˜è®¤1
            shortcut (bool): æ®‹å·®è¿æ¥æ ‡å¿—ï¼Œé»˜è®¤True
            g (int): å·ç§¯åˆ†ç»„æ•°ï¼Œé»˜è®¤1
            e (float): æ‰©å±•æ¯”ä¾‹ï¼Œé»˜è®¤0.5
        """
        super().__init__()
        self.c = int(c2 * e)  # hidden channels

        # Input processing
        self.cv1 = nn.Sequential(
            nn.Conv2d(c1, 2 * self.c, 1, 1, bias=False),
            nn.BatchNorm2d(2 * self.c),
            nn.SiLU()
        )

        # DCN+SCC bottleneck blocks
        self.m = nn.ModuleList(
            DCN_SCC_Bottleneck(self.c, self.c, shortcut=shortcut, g=g)
            for _ in range(n)
        )

        # Output processing
        self.cv2 = nn.Sequential(
            nn.Conv2d((2 + n) * self.c, c2, 1, 1, bias=False),
            nn.BatchNorm2d(c2),
            nn.SiLU()
        )

    def forward(self, x):
        """
        å‰å‘ä¼ æ’­

        å‚æ•°ï¼š
            x (torch.Tensor): è¾“å…¥ç‰¹å¾å›¾ [B, C1, H, W]

        è¿”å›ï¼š
            torch.Tensor: è¾“å‡ºç‰¹å¾å›¾ [B, C2, H, W]
        """
        # Split and process
        y = list(self.cv1(x).chunk(2, 1))

        # Apply DCN+SCC bottlenecks
        for m in self.m:
            y.append(m(y[-1]))

        # Concatenate and output
        return self.cv2(torch.cat(y, 1))
